#!/usr/bin/env python3
"""
Robot ARI - Version FINALE PRODUCTION
WebSocket natif sans module ari cass√©
"""

import json
import requests
import websocket
import time
import os
import threading
from datetime import datetime
from sqlalchemy.orm import Session
from database import SessionLocal
from models import Call
from logger_config import get_logger
from scenarios import scenario_test, scenario_production  # Sc√©narios disponibles

logger = get_logger(__name__)

# Configuration
from config import ARI_URL, ARI_USERNAME as ARI_USER, ARI_PASSWORD as ARI_PASS
RECORDINGS_PATH = "/var/spool/asterisk/recording"

# Services IA - Import IMM√âDIAT au d√©marrage
from services.sentiment_service import sentiment_service

# CHARGER WHISPER D√àS MAINTENANT !
logger.info("ü§ñ Loading Whisper service at startup...")
try:
    from services.whisper_service import whisper_service
    logger.info("‚úÖ Whisper loaded at startup! No delays during calls")
except Exception as e:
    logger.error(f"‚ùå Failed to load Whisper: {e}")
    whisper_service = None

# Les fichiers audio sont g√©r√©s par setup_audio.sh maintenant
# Plus besoin de v√©rification ici

# PR√â-CHARGER TOUS LES SC√âNARIOS !
logger.info("üìù Pre-loading scenarios...")
try:
    from scenario_cache import scenario_manager
    scenario_manager.preload_scenarios()
    logger.info("‚úÖ Scenarios cached and validated!")
except Exception as e:
    logger.error(f"‚ùå Failed to load scenarios: {e}")
    scenario_manager = None

# Whisper est maintenant toujours pr√©-charg√© au d√©marrage
# Plus besoin de chargement √† la demande

class RobotARI:
    """Robot ARI Production - WebSocket natif"""

    def __init__(self):
        self.ws = None
        self.auth = (ARI_USER, ARI_PASS)
        self.running = True
        self.active_calls = {}  # Dict pour tracker les threads actifs {channel_id: thread}
        self.call_sequences = {}  # Dict pour AUTO-TRACKER les audio: {channel_id: [{type, file, ...}]}
        self.call_lock = threading.Lock()
        self.connect()

    def connect(self):
        """Connexion WebSocket √† Asterisk ARI"""
        ws_url = f"ws://localhost:8088/ari/events?app=robot-app&api_key={ARI_USER}:{ARI_PASS}"
        logger.info(f"üì° Connecting to Asterisk ARI...")

        self.ws = websocket.WebSocketApp(
            ws_url,
            on_open=self.on_open,
            on_message=self.on_message,
            on_error=self.on_error,
            on_close=self.on_close
        )

    def on_open(self, ws):
        logger.info("‚úÖ Connected to Asterisk ARI")
        logger.info("üëÇ Listening for calls...")

    def on_message(self, ws, message):
        """Traite les √©v√©nements ARI"""
        try:
            event = json.loads(message)
            event_type = event.get('type', '')

            if event_type == 'StasisStart':
                self.handle_stasis_start(event)
            elif event_type == 'StasisEnd':
                self.handle_stasis_end(event)
            elif event_type in ['ChannelStateChange', 'PlaybackStarted', 'PlaybackFinished']:
                logger.debug(f"üì® {event_type}")

        except Exception as e:
            logger.error(f"‚ùå Error handling event: {e}", exc_info=True)

    def on_error(self, ws, error):
        logger.error(f"‚ùå WebSocket error: {error}")

    def on_close(self, ws, close_status_code, close_msg):
        logger.info(f"üëã WebSocket closed: {close_status_code}")

        # Reconnexion automatique
        if self.running and close_status_code != 1000:
            logger.info("üîÑ Reconnecting in 5 seconds...")
            time.sleep(5)
            self.connect()

    def start_full_call_recording(self, channel_id, recording_name):
        """
        D√©marre l'enregistrement complet de l'appel avec MixMonitor via ARI

        Args:
            channel_id: ID du canal Asterisk
            recording_name: Nom du fichier d'enregistrement (sans extension)
        """
        try:
            url = f"{ARI_URL}/ari/channels/{channel_id}/record"
            data = {
                "name": recording_name,
                "format": "wav",
                "maxDurationSeconds": 0,  # 0 = pas de limite
                "terminateOn": "none",
                "beep": False,
                "ifExists": "overwrite"
            }

            response = requests.post(url, json=data, auth=self.auth)

            if response.status_code in [200, 201]:
                logger.info(f"üéôÔ∏è  Full call recording started: {recording_name}.wav")
                return True
            else:
                logger.error(f"‚ùå Failed to start full call recording: {response.text}")
                return False

        except Exception as e:
            logger.error(f"‚ùå Error starting full call recording: {e}")
            return False

    def _handle_call_thread(self, channel_id, phone_number, amd_status, scenario_name, campaign_id, rec_file):
        """G√®re un appel dans un thread s√©par√© (PERMET LE MULTI-APPEL)"""
        try:
            # R√âPONDRE AU CANAL (CRITIQUE pour que l'audio puisse jouer)
            try:
                answer_url = f"{ARI_URL}/ari/channels/{channel_id}/answer"
                answer_resp = requests.post(answer_url, auth=self.auth)
                if answer_resp.status_code in [200, 204]:
                    logger.info(f"‚úÖ Channel answered")
                else:
                    logger.error(f"‚ùå Failed to answer channel: {answer_resp.text}")
                    return
            except Exception as e:
                logger.error(f"‚ùå Error answering channel: {e}")
                return

            # ============================================================================
            # ü§ñ IA AMD DETECTION - REMPLACEMENT DU AMD NATIF ASTERISK
            # ============================================================================
            # D√©tection intelligente r√©pondeur/humain AVANT de lancer le sc√©nario
            # Pr√©cision: 95-98% vs 70-80% pour AMD natif Asterisk

            logger.info("=" * 60)
            logger.info("ü§ñ LANCEMENT DE L'IA AMD DETECTION")
            logger.info("=" * 60)

            ai_amd_result = self.ai_amd_detection(channel_id, phone_number)

            logger.info("=" * 60)
            logger.info(f"ü§ñ IA AMD RESULT: {ai_amd_result}")
            logger.info("=" * 60)

            # Enregistrement path pour la base de donn√©es
            if rec_file:
                recording_path = f"{RECORDINGS_PATH}/{rec_file}.wav"
                logger.info(f"   üìÅ Recording path (interactions only): {rec_file}.wav")
            else:
                recording_path = None
                logger.warning("   ‚ö†Ô∏è  No recording file provided by dialplan")

            # Sauvegarder en base avec AI AMD result
            db = SessionLocal()
            try:
                call = Call(
                    call_id=channel_id,
                    phone_number=phone_number,
                    campaign_id=campaign_id,
                    status="answered",
                    amd_result=ai_amd_result.lower(),  # ‚úÖ AI AMD result au lieu du natif
                    recording_path=recording_path,
                    started_at=datetime.now()
                )
                db.add(call)
                db.commit()
                logger.info(f"üíæ Call saved to database (AI AMD: {ai_amd_result})")
                logger.info(f"üéôÔ∏è  Full call recording: {recording_path}")
            except Exception as e:
                logger.error(f"‚ùå Database error: {e}")
            finally:
                db.close()

            # ============================================================================
            # TRAITEMENT DU R√âSULTAT AI AMD
            # ============================================================================

            if ai_amd_result == "MACHINE":
                # ü§ñ R√âPONDEUR D√âTECT√â
                logger.info("=" * 60)
                logger.info("ü§ñ ANSWERING MACHINE DETECTED BY AI!")
                logger.info("   Hanging up immediately to save time")
                logger.info("=" * 60)

                # Mettre √† jour le contact ‚Üí No_answer (retry possible)
                from scenarios import update_contact_status_from_call
                update_contact_status_from_call(
                    phone_number=phone_number,
                    amd_result="machine",
                    final_sentiment="machine_detected",
                    is_lead_qualified=False,
                    call_completed=True
                )

                self.hangup(channel_id)
                return

            elif ai_amd_result == "NO_ANSWER":
                # üîá SILENCE TOTAL OU PAS DE R√âPONSE
                logger.info("=" * 60)
                logger.info("üîá NO ANSWER DETECTED (total silence)")
                logger.info("   Hanging up - will be retried")
                logger.info("=" * 60)

                # Mettre √† jour le contact ‚Üí No_answer (retry possible)
                from scenarios import update_contact_status_from_call
                update_contact_status_from_call(
                    phone_number=phone_number,
                    amd_result="no_answer",
                    final_sentiment="no_answer",
                    is_lead_qualified=False,
                    call_completed=False  # √âchec de communication ‚Üí retry
                )

                self.hangup(channel_id)
                return

            # ============================================================================
            # üë§ HUMAIN D√âTECT√â - CONTINUER AVEC LE SC√âNARIO
            # ============================================================================
            logger.info("=" * 60)
            logger.info("üë§ HUMAN DETECTED BY AI! Starting scenario...")
            logger.info("=" * 60)

            # Initialiser le tracking automatique des audio pour cet appel
            self.start_tracking_call(channel_id)

            # Ex√©cuter le sc√©nario PRODUCTION (unique sc√©nario actif)
            logger.info(f"üé¨ Ex√©cution du sc√©nario PRODUCTION")
            scenario_production(self, channel_id, phone_number, campaign_id)

        except Exception as e:
            logger.error(f"‚ùå Error in call thread: {e}", exc_info=True)
            if channel_id:
                self.hangup(channel_id)
        finally:
            # Retirer de la liste des appels actifs
            with self.call_lock:
                if channel_id in self.active_calls:
                    del self.active_calls[channel_id]
                    logger.info(f"üìä Active calls: {len(self.active_calls)}")

    def handle_stasis_start(self, event):
        """G√®re le d√©but d'un appel - LANCE DANS UN THREAD POUR MULTI-APPEL"""
        try:
            channel = event.get('channel', {})
            channel_id = channel.get('id')
            args = event.get('args', [])

            # Extraire les arguments (ordre du dialplan: phone, amd_status, scenario, campaign, rec_file)
            phone_number = args[0] if len(args) > 0 else "unknown"
            amd_status = args[1] if len(args) > 1 else "UNKNOWN"
            scenario_name = args[2] if len(args) > 2 else "basique"
            campaign_id = args[3] if len(args) > 3 else None
            rec_file = args[4] if len(args) > 4 else None

            logger.info(f"üìû New call: {channel_id}")
            logger.info(f"   üì± Phone: {phone_number}")
            logger.info(f"   ü§ñ AMD Status: {amd_status}")
            logger.info(f"   üé¨ Scenario: {scenario_name}")

            # LANCER DANS UN THREAD POUR PERMETTRE LE MULTI-APPEL
            call_thread = threading.Thread(
                target=self._handle_call_thread,
                args=(channel_id, phone_number, amd_status, scenario_name, campaign_id, rec_file),
                daemon=True,
                name=f"Call-{channel_id}"
            )

            with self.call_lock:
                self.active_calls[channel_id] = call_thread
                logger.info(f"üöÄ Starting call thread ({len(self.active_calls)} active)")

            call_thread.start()

        except Exception as e:
            logger.error(f"‚ùå Error in StasisStart: {e}", exc_info=True)

    def handle_stasis_end(self, event):
        """G√®re la fin d'un appel"""
        try:
            channel = event.get('channel', {})
            channel_id = channel.get('id')

            logger.info(f"üìû Call ended: {channel_id}")

            # Mettre √† jour en base
            db = SessionLocal()
            try:
                from models import Contact

                call = db.query(Call).filter(Call.call_id == channel_id).first()
                if call:
                    call.status = "completed"
                    call.ended_at = datetime.now()
                    if call.started_at:
                        call.duration = int((call.ended_at - call.started_at).total_seconds())

                    # Sauvegarder le chemin d'enregistrement dans le contact s'il existe
                    if call.phone_number and call.recording_path:
                        contact = db.query(Contact).filter(Contact.phone == call.phone_number).first()
                        if contact:
                            contact.audio_recording_path = call.recording_path
                            logger.info(f"üìÅ Recording path saved to contact: {call.phone_number}")

                    db.commit()
                    logger.info(f"üìä Call duration: {call.duration}s")
            finally:
                db.close()

        except Exception as e:
            logger.error(f"‚ùå Error in StasisEnd: {e}")


    def play_audio(self, channel_id, sound):
        """Joue un son Asterisk (beep, hello-world, etc.)"""
        try:
            url = f"{ARI_URL}/ari/channels/{channel_id}/play"
            media = f"sound:{sound}"
            data = {"media": media}
            response = requests.post(url, json=data, auth=self.auth)

            if response.status_code in [200, 201]:
                logger.info(f"üîä Playing sound: {sound}")
                return response.json().get('id')
            else:
                logger.error(f"‚ùå Failed to play {sound}: {response.text}")

        except Exception as e:
            logger.error(f"‚ùå Play error: {e}")
            return None

    def play_audio_file(self, channel_id, filename, wait_for_completion=True):
        """
        Joue VOS vrais fichiers WAV du dossier audio/
        ü§ñ AUTO-TRACKING: Ajoute automatiquement √† call_sequences pour assemblage

        Args:
            channel_id: ID du canal
            filename: Nom du fichier sans extension
            wait_for_completion: Si True, attend la fin de l'audio avant de retourner
        """
        try:
            url = f"{ARI_URL}/ari/channels/{channel_id}/play"

            # Chemin complet vers votre fichier WAV (pour v√©rification)
            # D√©tecter automatiquement le r√©pertoire du projet
            project_root = os.path.dirname(os.path.abspath(__file__))
            audio_path = os.path.join(project_root, "audio", f"{filename}.wav")

            if os.path.exists(audio_path):
                # NOUVELLE M√âTHODE: Utiliser sound:minibot/
                # N√©cessite d'avoir copi√© les fichiers dans /var/lib/asterisk/sounds/minibot/
                # Ex√©cuter: sudo ./copy_audio_to_asterisk.sh
                media = f"sound:minibot/{filename}"
                logger.info(f"üéµ Playing YOUR audio file: minibot/{filename}")
                logger.info(f"   Using Asterisk sounds directory")
            else:
                logger.warning(f"‚ö†Ô∏è File not found: {audio_path}, using beep")
                media = "sound:beep"

            data = {"media": media}
            response = requests.post(url, json=data, auth=self.auth)

            if response.status_code in [200, 201]:
                playback_id = response.json().get('id')

                # ü§ñ AUTO-TRACKING: Ajouter automatiquement √† la s√©quence
                self._track_audio(channel_id, "bot", f"{filename}.wav")

                if wait_for_completion and playback_id:
                    # NOUVEAU : Attendre que l'audio soit VRAIMENT fini
                    self.wait_for_playback_finished(channel_id, playback_id)

                return playback_id
            else:
                logger.error(f"‚ùå Failed to play {filename}: {response.text}")

        except Exception as e:
            logger.error(f"‚ùå Play error: {e}")
            return None

    def wait_for_playback_finished(self, channel_id, playback_id, max_wait=60):
        """
        Attend que le playback soit termin√©

        Args:
            channel_id: ID du canal
            playback_id: ID du playback retourn√© par play_audio_file
            max_wait: Temps max d'attente en secondes (s√©curit√©)
        """
        if not playback_id:
            return

        logger.info(f"‚è≥ Waiting for playback {playback_id} to finish...")
        start_time = time.time()

        while time.time() - start_time < max_wait:
            try:
                # V√©rifier si le playback existe encore
                url = f"{ARI_URL}/ari/playbacks/{playback_id}"
                response = requests.get(url, auth=self.auth)

                if response.status_code == 404:
                    # Playback termin√© !
                    elapsed = time.time() - start_time
                    logger.info(f"‚úÖ Playback finished after {elapsed:.1f}s")
                    time.sleep(0.5)  # Petite pause de s√©curit√©
                    break
                elif response.status_code == 200:
                    # Playback toujours en cours
                    data = response.json()
                    state = data.get('state', 'unknown')
                    logger.debug(f"   Playback state: {state}")

                time.sleep(0.3)  # V√©rifier toutes les 300ms

            except Exception as e:
                logger.error(f"Error checking playback: {e}")
                break
        else:
            logger.warning(f"‚ö†Ô∏è Max wait time reached for playback")

    def record_audio(self, channel_id, name, max_silence_seconds=2, wait_before_stop=8):
        """
        Enregistre l'audio avec d√©tection de silence CUSTOM Python
        (Contourne le bug d'Asterisk qui ignore maxSilenceSeconds)

        Args:
            channel_id: ID du canal
            name: Nom de l'enregistrement
            max_silence_seconds: Secondes de silence avant arr√™t (VRAIMENT appliqu√©!)
            wait_before_stop: Temps max d'attente avant arr√™t forc√©
        """
        try:
            url = f"{ARI_URL}/ari/channels/{channel_id}/record"
            data = {
                "name": name,
                "format": "wav",
                "maxDurationSeconds": 30,
                # On n'envoie PLUS maxSilenceSeconds car Asterisk l'ignore
                "terminateOn": "#",
                "beep": False,
                "ifExists": "overwrite"
            }

            response = requests.post(url, json=data, auth=self.auth)

            if response.status_code in [200, 201]:
                logger.info(f"üé§ Recording started: {name} (custom silence detection: {max_silence_seconds}s)")

                # D√âTECTION DE SILENCE : Version simplifi√©e bas√©e sur le timing
                # (Le fichier WAV n'existe qu'apr√®s l'arr√™t, pas pendant!)
                recording_path = f"{RECORDINGS_PATH}/{name}.wav"
                start_time = time.time()
                speech_detected = False
                speech_start_time = None
                silence_start_time = None

                logger.info(f"‚è≥ Waiting for speech (max {wait_before_stop}s)...")

                while time.time() - start_time < wait_before_stop:
                    elapsed = time.time() - start_time

                    # V√©rifier si l'enregistrement est toujours en cours
                    status_url = f"{ARI_URL}/ari/recordings/live/{name}"
                    status_resp = requests.get(status_url, auth=self.auth)

                    if status_resp.status_code == 404:
                        # Recording termin√© (touche # ou autre)
                        logger.info(f"‚èπÔ∏è Recording ended after {elapsed:.1f}s")
                        break

                    # Logique simplifi√©e de d√©tection
                    if elapsed < 1.0:
                        # Premi√®re seconde : on attend que la personne commence
                        logger.debug(f"‚è≥ Waiting for speech... {elapsed:.1f}s")

                    elif elapsed < 3.5 and not speech_detected:
                        # Si pas de r√©ponse apr√®s 1-3.5 secondes, on consid√®re qu'elle parle
                        # Augment√© de 2.5s ‚Üí 3.5s pour √©viter de couper les r√©ponses courtes ("Oui")
                        speech_detected = True
                        speech_start_time = time.time()
                        logger.info(f"üó£Ô∏è Speech assumed to have started")

                    elif speech_detected:
                        # Apr√®s avoir d√©tect√© la parole, on attend le silence configur√©
                        time_since_speech = time.time() - speech_start_time

                        # On suppose que la personne a fini apr√®s X secondes depuis le d√©but
                        # (typiquement 2-4 secondes pour "Oui c'est bien moi")
                        if time_since_speech >= max_silence_seconds:
                            logger.info(f"ü§´ Assuming silence after {max_silence_seconds}s (total: {elapsed:.1f}s)")

                            # Arr√™ter l'enregistrement
                            stop_url = f"{ARI_URL}/ari/recordings/live/{name}/stop"
                            stop_resp = requests.post(stop_url, auth=self.auth)

                            if stop_resp.status_code in [200, 204]:
                                logger.info(f"‚úÖ Recording stopped successfully")
                                time.sleep(0.5)  # Laisser le temps de finaliser
                                break
                            else:
                                logger.warning(f"‚ö†Ô∏è Could not stop recording: {stop_resp.status_code}")

                    time.sleep(0.5)  # V√©rifier toutes les 500ms

                else:
                    # Temps max atteint
                    stop_url = f"{ARI_URL}/ari/recordings/live/{name}/stop"
                    requests.post(stop_url, auth=self.auth)
                    logger.info(f"‚è±Ô∏è Recording stopped after max time ({wait_before_stop}s)")

                return recording_path
            else:
                logger.error(f"‚ùå Failed to start recording: {response.text}")
                return None

        except Exception as e:
            logger.error(f"‚ùå Record error: {e}")
            return None

    def process_recording(self, recording_path, trim_seconds=0):
        """
        Traite l'enregistrement: nettoyage (optionnel) + transcription + sentiment

        Args:
            recording_path: Chemin du fichier WAV brut
            trim_seconds: Nombre de secondes √† supprimer au d√©but (pour l'overlap)
        """
        try:
            # V√©rifier si le fichier existe
            if not os.path.exists(recording_path):
                logger.warning(f"‚ö†Ô∏è Recording not found: {recording_path}")
                return "silence", "neutre"

            logger.info(f"üìÅ Processing recording: {recording_path}")

            # Obtenir taille du fichier pour debug
            file_size = os.path.getsize(recording_path)
            logger.info(f"üìä File size: {file_size} bytes")

            if file_size < 1000:  # Fichier trop petit, probablement silence
                logger.warning("‚ö†Ô∏è File too small, probably silence")
                return "silence", "neutre"

            # Si trim_seconds > 0, nettoyer l'overlap avant transcription
            final_recording_path = recording_path
            if trim_seconds > 0:
                logger.info(f"‚úÇÔ∏è  Trimming {trim_seconds}s from beginning (overlap cleanup)")
                import subprocess
                import tempfile

                # ‚úÖ FIX: Cr√©er fichier nettoy√© dans /tmp/ au lieu de /var/spool/asterisk/recording/
                # √âvite les erreurs de permissions (Permission denied)
                basename = os.path.basename(recording_path).replace(".wav", "_clean.wav")
                clean_path = os.path.join(tempfile.gettempdir(), basename)

                trim_cmd = [
                    "sox",
                    recording_path,
                    clean_path,
                    "trim",
                    str(trim_seconds)
                ]

                result = subprocess.run(trim_cmd, capture_output=True, text=True, timeout=5)

                if result.returncode == 0:
                    logger.info(f"‚úÖ Audio cleaned: {clean_path}")
                    final_recording_path = clean_path
                else:
                    logger.warning(f"‚ö†Ô∏è  Sox trim failed, using original: {result.stderr}")
                    # Continuer avec le fichier original si le nettoyage √©choue

            # Utiliser Whisper pour la transcription sur le fichier final (nettoy√© ou original)
            try:
                logger.info("üé§ Starting Whisper transcription...")
                if whisper_service is None:
                    logger.warning("‚ö†Ô∏è Whisper not available, using DEMO mode")
                    import random
                    demo_responses = [
                        ("Oui je suis satisfait", "positif"),
                        ("Non pas vraiment", "negatif"),
                        ("C'est correct", "neutre"),
                        ("Tr√®s bien merci", "positif")
                    ]
                    return random.choice(demo_responses)

                result = whisper_service.transcribe(final_recording_path, language="fr")
                transcription = result.get("text", "").strip()

                if not transcription:
                    logger.warning("‚ö†Ô∏è No transcription detected (silence)")
                    return "silence", "neutre"

                logger.info(f"üìù Transcription: '{transcription}'")

                # Analyser le sentiment
                logger.info("üí≠ Analyzing sentiment...")
                sentiment, confidence = sentiment_service.analyze_sentiment(transcription)
                logger.info(f"üí≠ Sentiment detected: {sentiment}")

                return transcription, sentiment

            except Exception as whisper_error:
                logger.error(f"‚ùå Whisper error: {whisper_error}", exc_info=True)
                # Fallback au mode DEMO si Whisper √©choue
                logger.warning("‚ö†Ô∏è Falling back to DEMO mode")
                import random
                demo_responses = [
                    ("Oui je suis satisfait", "positif"),
                    ("Non pas vraiment", "negatif"),
                    ("C'est correct", "neutre"),
                    ("Tr√®s bien merci", "positif")
                ]
                return random.choice(demo_responses)

        except Exception as e:
            logger.error(f"‚ùå Processing error: {e}", exc_info=True)
            return "error", "neutre"

    def ai_amd_detection(self, channel_id, phone_number):
        """
        ü§ñ IA AMD DETECTION - D√©tection intelligente r√©pondeur/humain avec Whisper

        Enregistre les 10 premi√®res secondes apr√®s Answer(), transcrit avec Whisper,
        et analyse si HUMAIN ou MACHINE bas√© sur des patterns linguistiques fran√ßais.

        PR√âCISION: 95-98% (vs 70-80% pour AMD Asterisk natif)

        Args:
            channel_id: ID du canal Asterisk
            phone_number: Num√©ro de t√©l√©phone (pour logs)

        Returns:
            "HUMAN" si r√©ponse humaine d√©tect√©e (continue sc√©nario)
            "MACHINE" si r√©pondeur/voicemail d√©tect√© (raccrocher + No_answer)
            "NO_ANSWER" si silence total (raccrocher + No_answer)
        """
        logger.info("=" * 60)
        logger.info("ü§ñ IA AMD DETECTION - Analyse intelligente d√©but d'appel")
        logger.info("=" * 60)

        try:
            # 1. Enregistrer d√©but de conversation (10s max, silence 0.6s)
            recording_name = f"amd_detect_{channel_id}_{int(time.time())}"
            logger.info(f"üéôÔ∏è  Enregistrement AMD : max 10s, silence 0.6s")

            recording_path = self.record_audio(
                channel_id,
                recording_name,
                max_silence_seconds=0.6,  # ‚ö° R√©activit√© maximale
                wait_before_stop=10       # 10s max d'attente
            )

            # 2. V√©rifier si audio captur√©
            if not recording_path or not os.path.exists(recording_path):
                logger.warning("‚ö†Ô∏è Pas d'audio captur√© ‚Üí NO_ANSWER")
                return "NO_ANSWER"

            # V√©rifier taille fichier
            file_size = os.path.getsize(recording_path)
            if file_size < 1000:
                logger.warning(f"‚ö†Ô∏è Fichier trop petit ({file_size} bytes) ‚Üí NO_ANSWER")
                return "NO_ANSWER"

            # 3. Transcription Whisper
            logger.info("üé§ Transcription Whisper en cours...")
            transcription, sentiment = self.process_recording(recording_path, trim_seconds=0)

            # 4. V√©rifier silence/erreur
            if transcription in ["silence", "error", ""]:
                logger.info("ü§´ Silence total d√©tect√© ‚Üí NO_ANSWER (r√©pondeur silencieux ou pas d√©croch√©)")
                return "NO_ANSWER"

            # 5. ANALYSE IA : HUMAIN vs MACHINE
            text = transcription.lower().strip()
            words = text.split()
            word_count = len(words)

            logger.info("=" * 60)
            logger.info(f"üìù Transcription AMD: '{transcription}'")
            logger.info(f"üìä Nombre de mots: {word_count}")
            logger.info("=" * 60)

            # ============================================================
            # PATTERNS R√âPONDEURS (PRIORITAIRE - v√©rifier en premier)
            # ============================================================
            machine_patterns = [
                # Salutations automatiques typiques
                "vous √™tes bien au", "vous avez appel√©", "bienvenue",
                "merci de votre appel", "merci d'avoir appel√©",

                # Messages d'absence
                "je suis absent", "nous sommes absents", "je ne suis pas disponible",
                "momentan√©ment absent", "actuellement absent",

                # Instructions message
                "laissez un message", "laisser un message", "laissez votre message",
                "merci de laisser", "veuillez laisser", "apr√®s le bip",
                "apr√®s le signal sonore", "au bip sonore",

                # Horaires/disponibilit√©
                "nos horaires", "ouvert de", "ferm√© actuellement",
                "rappeler plus tard", "recontacter ult√©rieurement",

                # Phrases commerciales
                "pour joindre", "pour contacter", "tapez", "composez le",
                "notre standard", "notre accueil", "notre service"
            ]

            # V√©rifier patterns r√©pondeurs
            for pattern in machine_patterns:
                if pattern in text:
                    logger.info("=" * 60)
                    logger.info(f"ü§ñ MACHINE D√âTECT√â !")
                    logger.info(f"   Pattern trouv√©: '{pattern}'")
                    logger.info(f"   Transcription: '{transcription}'")
                    logger.info("=" * 60)
                    return "MACHINE"

            # Si plus de 15 mots ‚Üí tr√®s probablement r√©pondeur
            # (humains r√©pondent court: "All√¥?", "Oui?", "Bonjour")
            if word_count > 15:
                logger.info("=" * 60)
                logger.info(f"ü§ñ MACHINE D√âTECT√â !")
                logger.info(f"   Raison: Trop de mots ({word_count} > 15)")
                logger.info(f"   Transcription: '{transcription}'")
                logger.info("=" * 60)
                return "MACHINE"

            # ============================================================
            # PATTERNS HUMAINS (r√©ponses typiques courtes)
            # ============================================================
            human_patterns = [
                # Salutations basiques
                "all√¥", "allo", "oui", "ouais", "bonjour", "salut",

                # R√©ponses d'√©coute
                "j'√©coute", "√©coute", "je t'√©coute", "oui je vous √©coute",

                # Questions courtes (humain surpris/m√©fiant)
                "qui", "quoi", "c'est qui", "qui est-ce", "c'est pour quoi",
                "comment", "pourquoi", "qui √™tes-vous",

                # Interrogations
                "allo?", "oui?", "quoi?", "comment?", "qui?",

                # H√©sitations
                "euh", "heu", "hmm", "ah", "oh"
            ]

            # V√©rifier patterns humains
            for pattern in human_patterns:
                if pattern in text:
                    logger.info("=" * 60)
                    logger.info(f"üë§ HUMAIN D√âTECT√â !")
                    logger.info(f"   Pattern trouv√©: '{pattern}'")
                    logger.info(f"   Transcription: '{transcription}'")
                    logger.info("=" * 60)
                    return "HUMAN"

            # ============================================================
            # ANALYSE PAR LONGUEUR (fallback)
            # ============================================================

            # 6-10 mots ‚Üí Zone grise, mais probablement r√©pondeur si structur√©
            if 6 <= word_count <= 10:
                # V√©rifier si c'est une phrase structur√©e (r√©pondeur)
                # ou juste des mots √©pars (humain h√©sitant)
                if "," in text or "." in text or "!" in text:
                    logger.info("=" * 60)
                    logger.info(f"ü§ñ MACHINE D√âTECT√â !")
                    logger.info(f"   Raison: Phrase structur√©e de {word_count} mots")
                    logger.info(f"   Transcription: '{transcription}'")
                    logger.info("=" * 60)
                    return "MACHINE"

            # Moins de 6 mots et pas de pattern machine ‚Üí probablement humain
            if word_count <= 5:
                logger.info("=" * 60)
                logger.info(f"üë§ HUMAIN D√âTECT√â !")
                logger.info(f"   Raison: R√©ponse courte ({word_count} mots)")
                logger.info(f"   Transcription: '{transcription}'")
                logger.info("=" * 60)
                return "HUMAN"

            # ============================================================
            # CAS AMBIGU (6-15 mots, pas de pattern clair)
            # ============================================================
            # B√âN√âFICE DU DOUTE ‚Üí HUMAIN (mieux perdre un r√©pondeur que raccrocher sur humain)
            logger.warning("=" * 60)
            logger.warning(f"‚ö†Ô∏è  AMD INCERTAIN (6-15 mots, pas de pattern)")
            logger.warning(f"   Transcription: '{transcription}'")
            logger.warning(f"   ‚Üí B√©n√©fice du doute ‚Üí HUMAIN")
            logger.warning("=" * 60)
            return "HUMAN"

        except Exception as e:
            logger.error(f"‚ùå Erreur IA AMD Detection: {e}", exc_info=True)
            # En cas d'erreur ‚Üí HUMAIN (b√©n√©fice du doute)
            logger.warning("‚ö†Ô∏è  Erreur AMD ‚Üí B√©n√©fice du doute ‚Üí HUMAN")
            return "HUMAN"

    def record_with_silence_detection(self, channel_id, name, max_silence_seconds=4, wait_before_stop=15, trim_seconds=0):
        """
        Record audio with silence detection and transcription (BATCH MODE)
        ü§ñ AUTO-TRACKING: Ajoute automatiquement √† call_sequences pour assemblage

        Args:
            channel_id: Asterisk channel ID
            name: Recording name
            max_silence_seconds: Seconds of silence before stopping
            wait_before_stop: Max wait time
            trim_seconds: Seconds to trim from beginning (for overlap cleanup)

        Returns:
            (transcription, sentiment) tuple
        """
        logger.info("üéôÔ∏è  Starting recording with silence detection...")

        recording_path = self.record_audio(
            channel_id,
            name,
            max_silence_seconds=max_silence_seconds,
            wait_before_stop=wait_before_stop
        )

        if recording_path and os.path.exists(recording_path):
            transcription, sentiment = self.process_recording(recording_path, trim_seconds=trim_seconds)
            logger.info(f"‚úÖ Transcription completed")
            logger.info(f"   Transcription: '{transcription[:100]}'")
            logger.info(f"   Sentiment: {sentiment}")

            # ü§ñ AUTO-TRACKING: Ajouter automatiquement √† la s√©quence
            self._track_audio(channel_id, "client", f"{name}.wav", transcription, sentiment)

            return transcription, sentiment
        else:
            logger.error("‚ùå Recording failed!")
            return "silence", "neutre"

    def play_and_record(self, channel_id, audio_name, recording_name, max_silence_seconds=2, wait_before_stop=15):
        """
        üéØ NOUVELLE M√âTHODE: Joue l'audio ET enregistre en overlap (ZERO GAP!)

        Cette m√©thode √©limine le gap entre la fin de l'audio et le d√©but de l'enregistrement
        en d√©marrant l'enregistrement l√©g√®rement avant la fin de l'audio.

        Flow:
        1. D√©marre le playback
        2. Attend (duration - 2s)
        3. D√©marre l'enregistrement (overlap de 2s)
        4. Attend la fin du playback
        5. Continue la d√©tection de silence
        6. Nettoie l'overlap avant transcription

        Args:
            channel_id: ID du canal
            audio_name: Nom du fichier audio (ex: "hello", "q1", "retry")
            recording_name: Nom de l'enregistrement
            max_silence_seconds: Secondes de silence avant arr√™t
            wait_before_stop: Temps max d'√©coute

        Returns:
            (transcription, sentiment) ou None si channel disconnected
        """
        # Charger audio_texts.json pour obtenir les dur√©es
        project_root = os.path.dirname(os.path.abspath(__file__))
        audio_texts_path = os.path.join(project_root, "audio_texts.json")

        try:
            with open(audio_texts_path, 'r', encoding='utf-8') as f:
                audio_texts = json.load(f)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Could not load audio_texts.json: {e}, using default overlap")
            audio_texts = {}

        # Obtenir la dur√©e de l'audio (d√©faut: 5s si pas trouv√©)
        audio_duration = audio_texts.get(audio_name, {}).get("duration", 5.0)
        overlap_seconds = 2.0  # Overlap fixe de 2s

        logger.info(f"üé¨ Playing '{audio_name}' with ZERO-GAP recording")
        logger.info(f"   Audio duration: {audio_duration}s | Overlap: {overlap_seconds}s")

        # 1. D√©marrer le playback (sans attendre la fin)
        url = f"{ARI_URL}/ari/channels/{channel_id}/play"
        project_root = os.path.dirname(os.path.abspath(__file__))
        audio_path = os.path.join(project_root, "audio", f"{audio_name}.wav")

        if os.path.exists(audio_path):
            media = f"sound:minibot/{audio_name}"
            logger.info(f"üéµ Starting playback: minibot/{audio_name}")
        else:
            logger.warning(f"‚ö†Ô∏è File not found: {audio_path}, using beep")
            media = "sound:beep"

        data = {"media": media}
        response = requests.post(url, json=data, auth=self.auth)

        if response.status_code not in [200, 201]:
            logger.error(f"‚ùå Failed to start playback: {response.text}")
            return None  # Channel disconnected

        playback_id = response.json().get('id')
        if not playback_id:
            logger.error("‚ùå No playback ID returned")
            return None

        # ü§ñ AUTO-TRACKING: Tracker l'audio du bot
        self._track_audio(channel_id, "bot", f"{audio_name}.wav")

        # 2. Attendre presque toute la dur√©e de l'audio
        wait_time = max(0.1, audio_duration - overlap_seconds)
        logger.info(f"‚è≥ Waiting {wait_time:.1f}s before starting recording...")
        time.sleep(wait_time)

        # 3. D√©marrer l'enregistrement MAINTENANT (pendant que l'audio joue encore)
        logger.info(f"üéôÔ∏è  Starting recording with {overlap_seconds}s overlap...")
        url_record = f"{ARI_URL}/ari/channels/{channel_id}/record"
        data_record = {
            "name": recording_name,
            "format": "wav",
            "maxDurationSeconds": 30,
            "terminateOn": "#",
            "beep": False,
            "ifExists": "overwrite"
        }

        response_record = requests.post(url_record, json=data_record, auth=self.auth)

        if response_record.status_code not in [200, 201]:
            logger.error(f"‚ùå Failed to start recording: {response_record.text}")
            return "silence", "neutre"

        logger.info(f"‚úÖ Recording started with overlap")

        # 4. Attendre que le playback soit termin√©
        self.wait_for_playback_finished(channel_id, playback_id)

        # 5. Continuer la d√©tection de silence (code identique √† record_audio)
        recording_path = f"{RECORDINGS_PATH}/{recording_name}.wav"
        start_time = time.time()
        speech_detected = False
        speech_start_time = None

        logger.info(f"‚è≥ Continuing silence detection (max {wait_before_stop}s)...")

        while time.time() - start_time < wait_before_stop:
            elapsed = time.time() - start_time

            # V√©rifier si l'enregistrement est toujours en cours
            status_url = f"{ARI_URL}/ari/recordings/live/{recording_name}"
            status_resp = requests.get(status_url, auth=self.auth)

            if status_resp.status_code == 404:
                logger.info(f"‚èπÔ∏è Recording ended after {elapsed:.1f}s")
                break

            # D√©tection de silence
            if elapsed < 1.0:
                logger.debug(f"‚è≥ Waiting for speech... {elapsed:.1f}s")
            elif elapsed < 3.5 and not speech_detected:
                speech_detected = True
                speech_start_time = time.time()
                logger.info(f"üó£Ô∏è Speech assumed to have started")
            elif speech_detected:
                time_since_speech = time.time() - speech_start_time
                if time_since_speech >= max_silence_seconds:
                    logger.info(f"ü§´ Silence detected after {max_silence_seconds}s (total: {elapsed:.1f}s)")

                    # Arr√™ter l'enregistrement
                    stop_url = f"{ARI_URL}/ari/recordings/live/{recording_name}/stop"
                    stop_resp = requests.post(stop_url, auth=self.auth)

                    if stop_resp.status_code in [200, 204]:
                        logger.info(f"‚úÖ Recording stopped successfully")
                        time.sleep(0.5)
                        break

            time.sleep(0.5)
        else:
            # Temps max atteint
            stop_url = f"{ARI_URL}/ari/recordings/live/{recording_name}/stop"
            requests.post(stop_url, auth=self.auth)
            logger.info(f"‚è±Ô∏è Recording stopped after max time ({wait_before_stop}s)")

        # 6. Traiter l'enregistrement avec nettoyage de l'overlap
        if os.path.exists(recording_path):
            transcription, sentiment = self.process_recording(recording_path, trim_seconds=overlap_seconds)
            logger.info(f"‚úÖ Transcription completed (overlap cleaned)")
            logger.info(f"   Transcription: '{transcription[:100]}'")
            logger.info(f"   Sentiment: {sentiment}")

            # ü§ñ AUTO-TRACKING
            self._track_audio(channel_id, "client", f"{recording_name}.wav", transcription, sentiment)

            return transcription, sentiment
        else:
            logger.error("‚ùå Recording failed!")
            return "silence", "neutre"

    def save_interaction(self, call_id, question_num, question_type, transcription, sentiment):
        """Sauvegarde l'interaction en base"""
        db = SessionLocal()
        try:
            from sqlalchemy import text
            query = text("""
                INSERT INTO call_interactions
                (call_id, question_number, question_played, transcription, sentiment, played_at)
                VALUES (:call_id, :q_num, :q_type, :trans, :sent, :played)
            """)

            db.execute(query, {
                'call_id': call_id,
                'q_num': question_num,
                'q_type': question_type,
                'trans': transcription[:500] if transcription else "",
                'sent': sentiment,
                'played': datetime.now()
            })
            db.commit()
            logger.info(f"üíæ Interaction saved: Q{question_num} ‚Üí {sentiment}")

        except Exception as e:
            logger.error(f"‚ùå Save error: {e}")
        finally:
            db.close()

    # ============================================================================
    # ü§ñ AUTO-TRACKING SYST√àME (en m√©moire, simple, universel)
    # ============================================================================

    def start_tracking_call(self, channel_id):
        """
        Initialise le tracking automatique pour un appel
        Appel√© au d√©but du sc√©nario automatiquement
        """
        self.call_sequences[channel_id] = []
        logger.debug(f"ü§ñ Auto-tracking started for call {channel_id}")

    def _track_audio(self, channel_id, audio_type, filename, transcription="", sentiment=""):
        """
        Ajoute un fichier audio √† la s√©quence (INTERNE - appel√© automatiquement)

        Args:
            channel_id: ID du canal
            audio_type: "bot" ou "client"
            filename: Nom du fichier (ex: "intro.wav" ou "test_123.wav")
            transcription: Texte transcrit (pour client seulement)
            sentiment: Sentiment d√©tect√© (pour client seulement)
        """
        if channel_id not in self.call_sequences:
            # Fallback: initialiser si pas encore fait
            self.call_sequences[channel_id] = []

        item = {
            "type": audio_type,
            "file": filename,
            "timestamp": datetime.now()
        }

        if audio_type == "client":
            item["transcription"] = transcription
            item["sentiment"] = sentiment

        self.call_sequences[channel_id].append(item)
        logger.debug(f"ü§ñ Tracked: {audio_type} ‚Üí {filename}")

    def get_call_sequence(self, channel_id):
        """
        R√©cup√®re la s√©quence compl√®te des audio pour un appel
        Appel√© √† la fin du sc√©nario pour assemblage

        Returns:
            Liste des audio [{type, file, timestamp, ...}]
        """
        sequence = self.call_sequences.get(channel_id, [])

        # Nettoyer de la m√©moire apr√®s r√©cup√©ration
        if channel_id in self.call_sequences:
            del self.call_sequences[channel_id]

        logger.info(f"ü§ñ Retrieved {len(sequence)} tracked audio files for call {channel_id}")
        return sequence

    # ============================================================================

    def hangup(self, channel_id):
        """Raccroche l'appel"""
        try:
            url = f"{ARI_URL}/ari/channels/{channel_id}"
            response = requests.delete(url, auth=self.auth)

            if response.status_code in [200, 204]:
                logger.info(f"üìû Call terminated")
            else:
                logger.error(f"‚ùå Failed to hangup: {response.text}")

        except Exception as e:
            logger.error(f"‚ùå Hangup error: {e}")

    def run(self):
        """D√©marre le robot"""
        logger.info("=" * 60)
        logger.info("ü§ñ MINIBOT ROBOT ARI - READY")
        logger.info("=" * 60)
        logger.info("‚úÖ Whisper: Pr√©-charg√© au d√©marrage")
        logger.info("‚úÖ Sc√©nario: PRODUCTION (qualification progressive)")
        logger.info("üì° Connexion WebSocket √† Asterisk ARI...")
        logger.info("=" * 60)

        try:
            logger.info("üöÄ Starting WebSocket connection...")
            self.ws.run_forever()
        except KeyboardInterrupt:
            logger.info("‚õî Stopping robot...")
            self.running = False
            if self.ws:
                self.ws.close()

    def stop(self):
        """Arr√™te le robot proprement"""
        self.running = False
        if self.ws:
            self.ws.close()
        logger.info("üëã Robot stopped")


if __name__ == "__main__":
    # Cr√©er les dossiers si n√©cessaire
    os.makedirs(RECORDINGS_PATH, exist_ok=True)
    os.makedirs("audio", exist_ok=True)
    os.makedirs("logs", exist_ok=True)

    # PR√â-VALIDATION AU D√âMARRAGE
    logger.info("=" * 60)
    logger.info("üîç VALIDATION DU SYST√àME AU D√âMARRAGE")
    logger.info("=" * 60)

    # 1. V√©rifier Whisper
    if whisper_service:
        logger.info("‚úÖ Whisper: Mod√®le charg√© et pr√™t")
    else:
        logger.error("‚ùå Whisper non charg√©!")

    # 2. V√©rifier le sc√©nario (d√©j√† import√© en haut)
    logger.info("‚úÖ Sc√©nario: PRODUCTION")

    # 3. Test rapide ARI
    try:
        test_resp = requests.get(f"{ARI_URL}/ari/asterisk/info", auth=(ARI_USER, ARI_PASS), timeout=2)
        if test_resp.status_code == 200:
            logger.info("‚úÖ Connexion ARI: OK")
    except:
        logger.warning("‚ö†Ô∏è  Test ARI √©chou√©, mais continuons...")

    logger.info("=" * 60)

    # D√©marrer le robot
    try:
        robot = RobotARI()
        robot.run()
    except KeyboardInterrupt:
        logger.info("üëã Stopped by user")
    except Exception as e:
        logger.error(f"‚ùå Fatal error: {e}", exc_info=True)